#!/usr/bin/env node
/**
 * Multi-Tenant Migration Script
 * 
 * Run with: DATABASE_URL=... node scripts/run-migration.mjs
 * Or set DATABASE_URL in environment
 */

import { neon } from '@neondatabase/serverless';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __dirname = path.dirname(fileURLToPath(import.meta.url));

const DATABASE_URL = process.env.DATABASE_URL;

if (!DATABASE_URL) {
    console.error('âŒ DATABASE_URL environment variable is required');
    console.log('\nUsage: DATABASE_URL=... node scripts/run-migration.mjs');
    console.log('\nYou can get the DATABASE_URL from:');
    console.log('  1. Neon Console â†’ Your Project â†’ Connection Details');
    console.log('  2. Or from Cloudflare Dashboard â†’ Workers â†’ Your Worker â†’ Settings â†’ Variables');
    process.exit(1);
}

async function runMigration() {
    console.log('ðŸš€ Starting multi-tenant migration...');
    console.log(`ðŸ“¡ Connecting to database: ${DATABASE_URL.substring(0, 40)}...`);

    const sql = neon(DATABASE_URL);

    // Read migration file
    const migrationPath = path.join(__dirname, 'migrate-multi-tenant.sql');
    const migrationSQL = fs.readFileSync(migrationPath, 'utf-8');

    // Split into statements (simple split, handles most cases)
    // Remove comments and split by semicolons
    const statements = migrationSQL
        .split(/;[\s]*\n/)
        .map(s => s.trim())
        .filter(s => s.length > 0 && !s.startsWith('--'));

    console.log(`ðŸ“‹ Found ${statements.length} SQL statements to execute`);

    let successCount = 0;
    let errorCount = 0;

    for (let i = 0; i < statements.length; i++) {
        const stmt = statements[i];
        if (!stmt || stmt.length < 5) continue;

        // Extract first line for logging
        const firstLine = stmt.split('\n')[0].substring(0, 60);
        process.stdout.write(`  [${i + 1}/${statements.length}] ${firstLine}... `);

        try {
            await sql(stmt);
            console.log('âœ…');
            successCount++;
        } catch (err) {
            // Ignore certain "already exists" errors
            if (err.message.includes('already exists') ||
                err.message.includes('duplicate key') ||
                err.message.includes('relation') && err.message.includes('does not exist')) {
                console.log('â­ï¸  (skipped - already exists)');
                successCount++;
            } else {
                console.log(`âŒ ${err.message.substring(0, 80)}`);
                errorCount++;
            }
        }
    }

    console.log('\nðŸ“Š Migration Summary:');
    console.log(`   âœ… Successful: ${successCount}`);
    console.log(`   âŒ Errors: ${errorCount}`);

    // Verify key tables exist
    console.log('\nðŸ” Verifying migration...');

    try {
        const companies = await sql`SELECT COUNT(*) as count FROM companies`;
        console.log(`   âœ… companies table: ${companies[0].count} rows`);
    } catch (err) {
        console.log(`   âŒ companies table: ${err.message}`);
    }

    try {
        const creditConfig = await sql`SELECT COUNT(*) as count FROM credit_config`;
        console.log(`   âœ… credit_config table: ${creditConfig[0].count} rows`);
    } catch (err) {
        console.log(`   âŒ credit_config table: ${err.message}`);
    }

    try {
        const users = await sql`SELECT id, email, role, company_id FROM users LIMIT 3`;
        console.log(`   âœ… users table updated:`);
        for (const u of users) {
            console.log(`      - ${u.email}: role=${u.role}, company_id=${u.company_id || 'NULL'}`);
        }
    } catch (err) {
        console.log(`   âŒ users verification: ${err.message}`);
    }

    console.log('\nâœ¨ Migration complete!');
}

runMigration().catch(err => {
    console.error('ðŸ’¥ Migration failed:', err);
    process.exit(1);
});
